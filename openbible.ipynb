{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch sentencepiece tqdm\n",
        "\n",
        "!git clone https://github.com/churchstudio-org/openbible.git\n",
        "%cd ./openbible\n",
        "\n",
        "!python scripts/list_metadata.py https://github.com/churchstudio-org/openbible/raw/main/\n",
        "!cat metadata.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUdfkShVPqRe",
        "outputId": "a46a46d1-f0f3-48ad-e57c-9e8adfbead6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "['In the beginning God created the heaven and the earth.', 'And the earth was without form, and void; and darkness was upon the face of the deep. And the Spirit of God moved upon the face of the waters.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Livros: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [38:29<00:00, 35.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TraduÃ§Ã£o final salva em kjv_pt.json âœ…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from google.colab import files  # If you're running this on Colab\n",
        "\n",
        "# -------------------------------------------\n",
        "# 0. CUDA device check\n",
        "# -------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 1. Load metadata.json\n",
        "# -------------------------------------------\n",
        "with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2. Helper: Translate a batch of verses\n",
        "# -------------------------------------------\n",
        "def translate_batch(verses, tokenizer, model, batch_size=8):\n",
        "    \"\"\"Translate a list of verses in batches using the provided model and tokenizer.\"\"\"\n",
        "    translations = []\n",
        "    for i in range(0, len(verses), batch_size):\n",
        "        batch = verses[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        translated = model.generate(**inputs)\n",
        "        out = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "        translations.extend(out)\n",
        "    return translations\n",
        "\n",
        "# -------------------------------------------\n",
        "# 3. Helper: Split Bible JSON into per-book files\n",
        "# -------------------------------------------\n",
        "BOOK_NAMES = [\n",
        "    \"Genesis\", \"Exodus\", \"Leviticus\", \"Numbers\", \"Deuteronomy\",\n",
        "    \"Joshua\", \"Judges\", \"Ruth\", \"Samuel1\", \"Samuel2\",\n",
        "    \"Kings1\", \"Kings2\", \"Chronicles1\", \"Chronicles2\", \"Ezra\",\n",
        "    \"Nehemiah\", \"Esther\", \"Job\", \"Psalms\", \"Proverbs\",\n",
        "    \"Ecclesiastes\", \"SongOfSolomon\", \"Isaiah\", \"Jeremiah\", \"Lamentations\",\n",
        "    \"Ezekiel\", \"Daniel\", \"Hosea\", \"Joel\", \"Amos\",\n",
        "    \"Obadiah\", \"Jonah\", \"Micah\", \"Nahum\", \"Habakkuk\",\n",
        "    \"Zephaniah\", \"Haggai\", \"Zechariah\", \"Malachi\", \"Matthew\",\n",
        "    \"Mark\", \"Luke\", \"John\", \"Acts\", \"Romans\",\n",
        "    \"Corinthians1\", \"Corinthians2\", \"Galatians\", \"Ephesians\", \"Philippians\",\n",
        "    \"Colossians\", \"Thessalonians1\", \"Thessalonians2\", \"Timothy1\", \"Timothy2\",\n",
        "    \"Titus\", \"Philemon\", \"Hebrews\", \"James\", \"Peter1\",\n",
        "    \"Peter2\", \"John1\", \"John2\", \"John3\", \"Jude\",\n",
        "    \"Revelation\"\n",
        "]\n",
        "\n",
        "def split_bible_by_book(bible_data, version_dir):\n",
        "    \"\"\"Split the bible_data into one JSON file per book inside version_dir/books.\"\"\"\n",
        "    books_dir = os.path.join(version_dir, \"books\")\n",
        "    os.makedirs(books_dir, exist_ok=True)\n",
        "\n",
        "    for i, book in enumerate(bible_data):\n",
        "        book_name = BOOK_NAMES[i]\n",
        "        book_path = os.path.join(books_dir, f\"{book_name}.json\")\n",
        "        with open(book_path, \"w\", encoding=\"utf-8\") as bf:\n",
        "            json.dump(book, bf, ensure_ascii=False, indent=2)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 4. Process each metadata entry\n",
        "# -------------------------------------------\n",
        "generated_versions = []  # Keep track of versions that were translated now\n",
        "\n",
        "for entry in metadata:\n",
        "    version = entry.get(\"version\")\n",
        "    model_name = entry.get(\"model\")\n",
        "    source_version = entry.get(\"source\")\n",
        "\n",
        "    if not version:\n",
        "        continue  # Skip if no version specified\n",
        "\n",
        "    version_dir = os.path.join(os.getcwd(), version)\n",
        "    bible_path = os.path.join(version_dir, f\"bible.json\")\n",
        "\n",
        "    # Skip if already generated\n",
        "    if os.path.exists(bible_path):\n",
        "        print(f\"âœ… Skipping {version} (already exists)\")\n",
        "        continue\n",
        "\n",
        "    # If no model is provided, we can't translate\n",
        "    if not model_name:\n",
        "        print(f\"âš ï¸ No model specified for version '{version}', skipping.\")\n",
        "        continue\n",
        "\n",
        "    # If no source is provided, we can't translate\n",
        "    if not source_version:\n",
        "        print(f\"âš ï¸ No source specified for version '{version}', skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Load the model and tokenizer for this version\n",
        "    print(f\"\\nðŸŒ Translating version '{version}' using model '{model_name}'...\")\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "    # Translate the entire Bible\n",
        "    with open(os.path.join(source_version[0], \"bible.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "        source = json.load(f)\n",
        "\n",
        "    bible_translated = []\n",
        "    for book in tqdm(source, desc=f\"Translating {version}\", unit=\"book\"):\n",
        "        book_translated = []\n",
        "        for chapter in book:\n",
        "            chapter_translated = translate_batch(chapter, tokenizer, model)\n",
        "            book_translated.append(chapter_translated)\n",
        "        bible_translated.append(book_translated)\n",
        "\n",
        "    # Save translated Bible JSON\n",
        "    os.makedirs(version_dir, exist_ok=True)\n",
        "    with open(bible_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(bible_translated, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"ðŸ’¾ Saved {version}.json in {version_dir}\")\n",
        "\n",
        "    # Split into per-book files\n",
        "    split_bible_by_book(bible_translated, version_dir)\n",
        "    print(f\"ðŸ“š Split Bible into per-book JSON files in {version_dir}/books\")\n",
        "\n",
        "    generated_versions.append(version_dir)\n",
        "\n",
        "# -------------------------------------------\n",
        "# 5. Download generated versions as zip files (Colab)\n",
        "# -------------------------------------------\n",
        "if generated_versions:\n",
        "    for version_dir in generated_versions:\n",
        "        zip_name = f\"{os.path.basename(version_dir)}.zip\"\n",
        "        shutil.make_archive(os.path.splitext(zip_name)[0], 'zip', version_dir)\n",
        "        files.download(f\"{os.path.splitext(zip_name)[0]}.zip\")\n",
        "\n",
        "print(\"âœ… All processing finished.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
